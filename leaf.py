import os
import time
import tempfile
import streamlit as st
import pandas as pd
from PIL import Image as PILImage
from dotenv import load_dotenv
from google.oauth2 import service_account
from google.cloud import firestore
import firebase_admin
from firebase_admin import credentials as admin_credentials, firestore as admin_firestore
from vertexai import init
from vertexai.generative_models import GenerativeModel, Image, Part
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait, Select
from selenium.webdriver.support import expected_conditions as EC
from selenium.common.exceptions import StaleElementReferenceException
import requests
from bs4 import BeautifulSoup
from selenium.webdriver.chrome.service import Service

# --- LOAD ENVIRONMENT ---
load_dotenv()
PROJECT_ID  = os.getenv("PROJECT_ID")
LOCATION = os.getenv("LOCATION")
SERVICE_ACCOUNT_FILE = os.getenv("SERVICE_ACCOUNT_FILE")

# --- INIT GOOGLE SERVICES ---
credentials = service_account.Credentials.from_service_account_file(SERVICE_ACCOUNT_FILE)
init(project=PROJECT_ID, location=LOCATION, credentials=credentials)
model = GenerativeModel("gemini-2.0-flash-001")

admin_cred = admin_credentials.Certificate(SERVICE_ACCOUNT_FILE)
if not firebase_admin._apps:
    firebase_admin.initialize_app(admin_cred)
db = admin_firestore.client()

# --- STREAMLIT UI ---
st.set_page_config(page_title="Project Kisan", page_icon="üåæ")
st.title("üåæ Project Kisan ‚Äì Crop Disease Detection")

farmer_name = st.text_input("üë®‚Äçüåæ Enter Farmer's Name")
uploaded_file = st.file_uploader("üì∑ Upload Crop Leaf Image", type=["jpg", "jpeg", "png"])

if uploaded_file and st.button("Diagnose Disease"):
    st.image(uploaded_file, caption="Uploaded Image", use_container_width=True)
    with tempfile.NamedTemporaryFile(delete=False, suffix=".jpg") as tmp_file:
        img = PILImage.open(uploaded_file)
        img.save(tmp_file.name)
        image_path = tmp_file.name

    image_part = Part.from_image(Image.load_from_file(image_path))
    prompt = (
        "‡≤®‡≥Ä‡≤µ‡≥Å ‡≤ï‡≤∞‡≥ç‡≤®‡≤æ‡≤ü‡≤ï ‡≤∞‡≥à‡≤§‡≤∞‡≤ø‡≤ó‡≥Ü ‡≤∏‡≤π‡≤æ‡≤Ø ‡≤Æ‡≤æ‡≤°‡≤ø‡≤§‡≥ç‡≤§‡≤ø‡≤¶‡≥ç‡≤¶‡≥Ä‡≤∞‡≤ø. \n"
        "‡≤à ‡≤∏‡≤∏‡≥ç‡≤Ø‡≤¶ ‡≤é‡≤≤‡≥Ü‡≤Ø ‡≤ö‡≤ø‡≤§‡≥ç‡≤∞‡≤µ‡≤®‡≥ç‡≤®‡≤®‡≥ç‡≤®‡≥Å ‡≤®‡≥ã‡≤°‡≤ø. \n"
        "‡≤¶‡≤Ø‡≤µ‡≤ø‡≤ü‡≥ç‡≤ü‡≥Å ‡≤ï‡≤∞‡≥ç‡≤®‡≤æ‡≤ü‡≤ï‡≤¶ ‡≤π‡≤µ‡≤æ‡≤Æ‡≤æ‡≤® ‡≤Æ√ä4‡≥ç‡≤§‡≥Å ‡≤ï‡≥É‡≤∑‡≤ø ‡≤™‡≤∞‡≤ø‡≤∏‡≥ç‡≤•‡≤ø‡≤§‡≤ø‡≤Ø‡≤®‡≥ç‡≤® ‡≤Ü‡≤ß‡≤æ‡≤∞‡≤ø‡≤∏‡≤ø, ‡≤à ‡≤é‡≤≤‡≥Ü‡≤Ø‡≤ø‡≤≤‡≥ç‡≤≤‡≤ø ‡≤ï‡≤Ç‡≤°‡≥Å‡≤¨‡≤∞‡≤µ ‡≤∞‡≥ã‡≤ó ‡≤Ö‡≤•‡≤µ‡≤æ ‡≤ï‡≥Ä‡≤ü‡≤™‡≥Ä‡≤°‡≥Ü ‡≤Ø‡≤æ‡≤µ‡≤¶‡≥Å ‡≤é√ã2‡≥ç‡≤≤‡≤ø ‡≤ó‡≥Å‡≤∞‡≥Å‡≤§‡≤ø‡≤∏‡≤ø."
    )

    try:
        response = model.generate_content([prompt, image_part])
        result = response.text
        st.success("‚úÖ Diagnosis in Kannada:")
        st.markdown(result)
        db.collection("diagnosis").add({
            "farmer": farmer_name,
            "diagnosis": result,
            "image_name": uploaded_file.name
        })
        st.info("üìú Diagnosis saved to Firebase")
    except Exception as e:
        st.error(f"‚ùå Something went wrong: {e}")

st.set_page_config(page_title="üßë‚Äçüåæ Farmer Scheme Assistant", page_icon="üåø")
st.title("üåø Government Scheme Helper")

user_query = st.text_input("Ask about schemes (e.g., subsidies for drip irrigation):")

if user_query and st.button("Search Schemes"):
    with st.spinner("Checking government portals..."):
        prompt = (
            f"‡≤®‡≥Ä‡≤µ‡≥Å ‡≤≠‡≤æ‡≤∞‡≤§‡≥Ä‡≤Ø ‡≤∞‡≥à‡≤§‡≤∞‡≤ø‡≤ó‡≥Ü –∞—Ä–Ω–∞–ª“ì–∞–Ω ‡≤∏‡≤∞‡≤ï‡≤æ‡≤∞‡≥Ä ‡≤Ø‡≥ã‡≤ú‡≤®‡≥Ü ‡≤∏‡≤π‡≤æ‡≤Ø‡≤ï.\n"
            f"‡≤∏‡≤∞‡≤≥ ‡≤ï‡≤®‡≥ç‡≤®‡≤°‡≤¶‡≤≤‡≥ç‡≤≤‡≤ø ‡≤â‡≤§‡≥ç‡≤§‡≤∞‡≤ø‡≤∏‡≥Å. ‡≤∞‡≥à‡≤§‡≤®‡≥Å ‡≤ï‡≥á‡≤≥‡≤ø‡≤¶ ‡≤™‡≥ç‡≤∞‡≤∂‡≥ç‡≤®‡≥Ü: {user_query}.\n"
            f"‡≤¶‡≤Ø‡≤µ‡≤ø‡≤ü‡≥ç‡≤ü‡≥Å ‡≤à ‡≤Æ‡≤æ‡≤π‡≤ø‡≤§‡≤ø ‡≤®‡≥Ä‡≤°‡≤ø: 1. ‡≤Ø‡≥ã‡≤ú‡≤®‡≥Ü‡≤Ø ‡≤π‡≥Ü‡≤∏‡≤∞‡≥Å 2. ‡≤Ö‡≤∞‡≥ç‡≤π‡≤§‡≥Ü 3. ‡≤≤‡≤æ‡≤≠‡≤ó‡≤≥‡≥Å 4. ‡≤Ö‡≤∞‡≥ç‡≤ú‡≤ø ‡≤π‡≤æ‡≤ï‡≤≤‡≥Å ‡≤≤‡≤ø‡≤Ç‡≤ï‡≥ç\n"
            f"‡≤ï‡≥Ü‡≤µ‡≤≤ ‡≤≠‡≤æ‡≤∞‡≤§‡≤¶ ‡≤∏‡≤∞‡≤ï‡≤æ‡≤∞‡≤¶ ‡≤Ø‡≥ã‡≤ú‡≤®‡≥Ü‡≤ó‡≤≥‡≤®‡≥ç‡≤®‡≥á ‡≤¨‡≤≥‡≤∏‡≤ø ‡≤Æ‡≤§‡≥ç‡≤§‡≥Å ‡≤á‡≤§‡≥ç‡≤§‡≥Ä‡≤ö‡≤ø‡≤® 2024-2025 ‡≤Æ‡≤æ‡≤π‡≤ø‡≤§‡≤ø‡≤Ø‡≤®‡≥ç‡≤®‡≤∑‡≥ç‡≤ü‡≥á ‡≤ï‡≥ä‡≤°‡≥Å."
        )

        try:
            response = model.generate_content(prompt)
            st.success("‚úÖ Schemes Found")
            st.markdown(response.text)
        except Exception as e:
            st.error(f"‚ùå Failed to fetch schemes: {e}")

global driver
global service
global wait
def scrape_agmarknet_prices(state, market, commodity):
    service = Service(r"C:\Users\prana\OneDrive\Desktop\chromedriver-win64\chromedriver.exe")
    driver = webdriver.Chrome(service=service)
    # driver = webdriver.Chrome()
    # driver.get("https://agmarknet.gov.in/PriceAndArrivals/CommodityPricesWeeklyReport.aspx")
    wait = WebDriverWait(driver, 20)
    driver.get("https://agmarknet.gov.in/PriceAndArrivals/CommodityPricesWeeklyReport.aspx")
    def safe_select(by, locator):
        for _ in range(3):
            try:
                element = driver.find_element(by, locator)
                return Select(element)
            except StaleElementReferenceException:
                time.sleep(1)
        raise Exception(f"Element not stable: {locator}")

    def wait_for_min_options(by, locator, min_count=2, timeout=20):
        def check_count(d):
            for _ in range(3):
                try:
                    select = Select(d.find_element(by, locator))
                    return len(select.options) >= min_count
                except StaleElementReferenceException:
                    time.sleep(1)
            return False
        WebDriverWait(driver, timeout).until(check_count)

    # Interactions
    safe_select(By.ID, "cphBody_cboState").select_by_visible_text(state)
    wait_for_min_options(By.ID, "cphBody_cboMarket", 2)
    safe_select(By.ID, "cphBody_cboMarket").select_by_visible_text(market)
    wait_for_min_options(By.ID, "cphBody_cboCommodity", 2)
    safe_select(By.ID, "cphBody_cboCommodity").select_by_visible_text(commodity)

    wait.until(EC.element_to_be_clickable((By.ID, "cphBody_btnSubmit"))).click()

    try:
        table = wait.until(EC.presence_of_element_located((By.ID, "cphBody_gridRecords")))
        rows = table.find_elements(By.TAG_NAME, "tr")

        if len(rows) <= 1:
            # Try to print the table HTML for debugging
            table_html = table.get_attribute("outerHTML") if table else "[No table element found]"
            print("[DEBUG] Table HTML when no rows found:\n", table_html)
            return pd.DataFrame()

        data = []
        for row in rows:
            cols = [td.text.strip() for td in row.find_elements(By.TAG_NAME, "td")]
            if cols:
                data.append(cols)

        # If data is not empty, try to get headers from the first row
        if data:
            headers = data[0]
            data_rows = data[1:] if len(data) > 1 else []
            df = pd.DataFrame(data_rows, columns=headers)
        else:
            df = pd.DataFrame()
        return df

    except Exception as e:
        # Print the page source for debugging
        try:
            page_html = driver.page_source
            print("[DEBUG] Page HTML on exception:\n", page_html[:2000], "... [truncated]")
        except Exception:
            print("[DEBUG] Could not get page source.")
        print(f"Error extracting table: {e}")
        return pd.DataFrame({'Error': [f'Error extracting table: {e}']})
    finally:
        driver.quit()
        

# --- STREAMLIT SCRAPER UI ---
def display_scraped_data():
    st.header("üìà Market Price Analysis for Karnataka")
    col1, col2 = st.columns(2)
    with col1:
        market = st.selectbox("Select Market", ["--", "Chintamani", "Bangarpet", "BENGALURU", "MYSORE"])
    with col2:
        commodity = st.selectbox("Select Commodity", ["--", "Potato", "Lime", "Tomato", "Rice", "Wheat"])

    if st.button("üîç Scrape Market Prices"):
        if market == "--" or commodity == "--":
            st.warning("‚ö†Ô∏è Please select valid options for Market and Commodity.")
        else:
            with st.spinner("Scraping market data..."):
                df = scrape_agmarknet_prices("Karnataka", market, commodity)

                if isinstance(df, pd.DataFrame) and not df.empty:
                    st.subheader("üìä Raw Table")
                    st.dataframe(df)
                    try:
                        # Reshape for line chart
                        df_long = df.melt(id_vars="Varieties", var_name="Date", value_name="Price")
                        df_long["Date"] = pd.to_datetime(df_long["Date"], dayfirst=True, errors="coerce")
                        df_long["Price"] = pd.to_numeric(df_long["Price"].replace("NR", None), errors="coerce")
                        df_long = df_long.dropna(subset=["Date", "Price"]).sort_values("Date")
                        st.subheader("üìà Price Trend")
                        st.line_chart(df_long.set_index("Date")["Price"])
                    except Exception as e:
                        st.error(f"‚ö†Ô∏è Could not plot line chart: {e}")
                elif isinstance(df, pd.DataFrame) and 'Error' in df.columns:
                    st.error(df['Error'].iloc[0])
                else:
                    st.error("‚ùå No data found for the selected options.")


# Add the scraping section
st.markdown("---")
display_scraped_data()